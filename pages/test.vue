<template>
  <div style="display: flex;justify-content: center">
    <el-button @click="modeltest">test linear model</el-button>
    <el-button @click="run">car test</el-button>
  </div>
</template>

<script>
  import * as tf from '@tensorflow/tfjs';
  import * as tfvis from '@tensorflow/tfjs-vis'

  export default {
    name: "test",
    methods: {

      modeltest() {
        console.log('Hello TensorFlow');

        //定义一个线性回归模型。
        const model = tf.sequential();
        model.add(tf.layers.dense({units: 1, inputShape: [1]}));
        model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});

        // 为训练生成一些合成数据
        const xs = tf.tensor2d([1, 2, 3, 4], [4, 1]);
        const ys = tf.tensor2d([1, 3, 5, 7], [4, 1]);

        // 使用数据训练模型
        model.fit(xs, ys, {epochs: 10}).then(() => {
          // 在该模型从未看到过的数据点上使用模型进行推理
          model.predict(tf.tensor2d([5], [1, 1])).print();
          //  打开浏览器开发工具查看输出
        });
      },

      async getData() {
        console.log('start fetch json')
        const carsDataReq = await fetch('https://storage.googleapis.com/tfjs-tutorials/carsData.json');
        const carsData = await carsDataReq.json();
        const cleaned = carsData.map(car => ({
          mpg: car.Miles_per_Gallon,
          horsepower: car.Horsepower,
        }))
          .filter(car => (car.mpg != null && car.horsepower != null));

        return cleaned;
      },

      async run() {
        // Load and plot the original input data that we are going to train on.
        const data = await this.getData();
        const values = data.map(d => ({
          x: d.horsepower,
          y: d.mpg,
        }));

        tfvis.render.scatterplot(
          {name: 'Horsepower v MPG'},
          {values},
          {
            xLabel: 'Horsepower',
            yLabel: 'MPG',
            height: 300
          }
        );

        // Create the model
        const model = this.createModel();
        tfvis.show.modelSummary({name: 'Model Summary'}, model);

        // Convert the data to a form we can use for training.
        const tensorData = this.convertToTensor(data);
        const {inputs, labels} = tensorData;

        // Train the model
        await this.trainModel(model, inputs, labels);
        console.log('Done Training');

        // Make some predictions using the model and compare them to the
        // original data
        this.testModel(model, data, tensorData);


      },
      createModel() {
        // Create a sequential model
        const model = tf.sequential();

        // Add a single hidden layer
        model.add(tf.layers.dense({inputShape: [1], units: 1, useBias: true}));

        model.add(tf.layers.dense({units: 50, activation: 'sigmoid'}));

        // Add an output layer
        model.add(tf.layers.dense({units: 1, useBias: true}));

        return model;
      },
      convertToTensor(data) {
        // Wrapping these calculations in a tidy will dispose any
        // intermediate tensors.

        return tf.tidy(() => {
          // Step 1. Shuffle the data
          tf.util.shuffle(data);

          // Step 2. Convert data to Tensor
          const inputs = data.map(d => d.horsepower)
          const labels = data.map(d => d.mpg);

          const inputTensor = tf.tensor2d(inputs, [inputs.length, 1]);
          const labelTensor = tf.tensor2d(labels, [labels.length, 1]);

          //Step 3. Normalize the data to the range 0 - 1 using min-max scaling
          const inputMax = inputTensor.max();
          const inputMin = inputTensor.min();
          const labelMax = labelTensor.max();
          const labelMin = labelTensor.min();

          const normalizedInputs = inputTensor.sub(inputMin).div(inputMax.sub(inputMin));
          const normalizedLabels = labelTensor.sub(labelMin).div(labelMax.sub(labelMin));

          return {
            inputs: normalizedInputs,
            labels: normalizedLabels,
            // Return the min/max bounds so we can use them later.
            inputMax,
            inputMin,
            labelMax,
            labelMin,
          }
        });
      },
      async trainModel(model, inputs, labels) {
        // Prepare the model for training.
        model.compile({
          optimizer: tf.train.adam(),
          loss: tf.losses.meanSquaredError,
          metrics: ['mse'],
        });

        const batchSize = 32;
        const epochs = 50;

        return await model.fit(inputs, labels, {
          batchSize,
          epochs,
          shuffle: true,
          callbacks: tfvis.show.fitCallbacks(
            {name: 'Training Performance'},
            ['loss', 'mse'],
            {height: 200, callbacks: ['onEpochEnd']}
          )
        });
      },
      testModel(model, inputData, normalizationData) {
        const {inputMax, inputMin, labelMin, labelMax} = normalizationData;

        // Generate predictions for a uniform range of numbers between 0 and 1;
        // We un-normalize the data by doing the inverse of the min-max scaling
        // that we did earlier.
        const [xs, preds] = tf.tidy(() => {

          const xs = tf.linspace(0, 1, 100);
          const preds = model.predict(xs.reshape([100, 1]));

          const unNormXs = xs
            .mul(inputMax.sub(inputMin))
            .add(inputMin);

          const unNormPreds = preds
            .mul(labelMax.sub(labelMin))
            .add(labelMin);

          // Un-normalize the data
          return [unNormXs.dataSync(), unNormPreds.dataSync()];
        });


        const predictedPoints = Array.from(xs).map((val, i) => {
          return {x: val, y: preds[i]}
        });

        const originalPoints = inputData.map(d => ({
          x: d.horsepower, y: d.mpg,
        }));


        tfvis.render.scatterplot(
          {name: 'Model Predictions vs Original Data'},
          {values: [originalPoints, predictedPoints], series: ['original', 'predicted']},
          {
            xLabel: 'Horsepower',
            yLabel: 'MPG',
            height: 300
          }
        );
      }


    }
  }
</script>

<style scoped>

</style>
